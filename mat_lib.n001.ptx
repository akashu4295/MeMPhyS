//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36260728
// Cuda compilation tools, release 13.0, V13.0.48
// Based on NVVM 7.0.1
//

.version 9.0
.target sm_80
.address_size 64

	// .globl	_22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu
.extern .shared .align 8 .b8 S26_2[];

.visible .entry _22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu(
	.param .u32 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_0,
	.param .u32 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_1,
	.param .u64 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_2,
	.param .u64 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_3,
	.param .u64 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_4,
	.param .u64 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_5,
	.param .u32 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_6
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<11>;
	.reg .b32 	%r<44>;
	.reg .f64 	%fd<32>;
	.reg .b64 	%rd<55>;
	.loc	1 34 0


	ld.param.u32 	%r21, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_0];
	ld.param.u32 	%r22, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_1];
	ld.param.u64 	%rd15, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_2];
	ld.param.u64 	%rd18, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_3];
	ld.param.u64 	%rd16, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_4];
	ld.param.u64 	%rd17, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_5];
	ld.param.u32 	%r23, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_vectorised_gpu_34_gpu_param_6];
	.loc	1 34 1
	cvta.to.global.u64 	%rd1, %rd18;
	mov.u32 	%r24, %ctaid.x;
	mul.wide.s32 	%rd19, %r24, 128;
	mov.u32 	%r25, %tid.x;
	cvt.s64.s32 	%rd20, %r25;
	add.s64 	%rd53, %rd19, %rd20;
	.loc	1 54 1
	mov.u32 	%r26, %nctaid.x;
	mul.wide.s32 	%rd3, %r26, 128;
	cvt.u32.u64 	%r1, %rd3;
	setp.lt.s32 	%p1, %r21, 1;
	.loc	1 49 1
	@%p1 bra 	$L__BB0_12;

	.loc	1 0 1
	and.b32  	%r2, %r21, 3;
	add.s32 	%r3, %r21, -2;
	add.s32 	%r4, %r21, -3;
	mov.u32 	%r38, %r22;

$L__BB0_2:
	.pragma "nounroll";
	cvt.u32.u64 	%r27, %rd53;
	.loc	1 43 1
	mul.lo.s32 	%r6, %r27, %r23;
	setp.ge.s32 	%p2, %r27, %r22;
	@%p2 bra 	$L__BB0_11;

	.loc	1 0 1
	setp.eq.s32 	%p3, %r2, 0;
	mov.f64 	%fd31, 0d0000000000000000;
	.loc	1 49 1
	mov.u32 	%r39, %r6;
	mov.u32 	%r40, %r21;
	@%p3 bra 	$L__BB0_7;

	.loc	1 0 1
	setp.eq.s32 	%p4, %r2, 1;
	.loc	1 50 1
	mul.wide.s32 	%rd21, %r6, 4;
	add.s64 	%rd5, %rd1, %rd21;
	ld.global.nc.u32 	%r28, [%rd5];
	.loc	1 34 1
	cvta.to.global.u64 	%rd22, %rd16;
	.loc	1 52 1
	mul.wide.s32 	%rd23, %r28, 8;
	add.s64 	%rd24, %rd22, %rd23;
	.loc	1 34 1
	cvta.to.global.u64 	%rd25, %rd17;
	.loc	1 52 1
	mul.wide.s32 	%rd26, %r6, 8;
	add.s64 	%rd6, %rd25, %rd26;
	ld.global.f64 	%fd11, [%rd6];
	ld.global.f64 	%fd12, [%rd24];
	fma.rn.f64 	%fd31, %fd12, %fd11, 0d0000000000000000;
	add.s32 	%r39, %r6, 1;
	add.s32 	%r40, %r21, -1;
	.loc	1 49 1
	@%p4 bra 	$L__BB0_7;

	.loc	1 0 1
	setp.eq.s32 	%p5, %r2, 2;
	.loc	1 50 1
	ld.global.nc.u32 	%r29, [%rd5+4];
	.loc	1 52 1
	mul.wide.s32 	%rd28, %r29, 8;
	add.s64 	%rd29, %rd22, %rd28;
	ld.global.f64 	%fd13, [%rd6+8];
	ld.global.f64 	%fd14, [%rd29];
	fma.rn.f64 	%fd31, %fd14, %fd13, %fd31;
	add.s32 	%r39, %r6, 2;
	.loc	1 49 1
	mov.u32 	%r40, %r3;
	@%p5 bra 	$L__BB0_7;

	.loc	1 50 1
	ld.global.nc.u32 	%r30, [%rd5+8];
	.loc	1 52 1
	mul.wide.s32 	%rd31, %r30, 8;
	add.s64 	%rd32, %rd22, %rd31;
	ld.global.f64 	%fd15, [%rd6+16];
	ld.global.f64 	%fd16, [%rd32];
	fma.rn.f64 	%fd31, %fd16, %fd15, %fd31;
	add.s32 	%r39, %r6, 3;
	mov.u32 	%r40, %r4;

$L__BB0_7:
	.loc	1 0 1
	add.s32 	%r31, %r21, -1;
	setp.lt.u32 	%p6, %r31, 3;
	.loc	1 49 1
	@%p6 bra 	$L__BB0_10;

	add.s32 	%r41, %r39, 3;
	.loc	1 34 1
	cvta.to.global.u64 	%rd9, %rd17;
	cvta.to.global.u64 	%rd10, %rd16;

$L__BB0_9:
	.loc	1 50 1
	add.s32 	%r32, %r41, -3;
	mul.wide.s32 	%rd33, %r32, 4;
	add.s64 	%rd34, %rd1, %rd33;
	ld.global.nc.u32 	%r33, [%rd34];
	.loc	1 52 1
	mul.wide.s32 	%rd35, %r33, 8;
	add.s64 	%rd36, %rd10, %rd35;
	mul.wide.s32 	%rd37, %r32, 8;
	add.s64 	%rd38, %rd9, %rd37;
	ld.global.f64 	%fd17, [%rd38];
	ld.global.f64 	%fd18, [%rd36];
	fma.rn.f64 	%fd19, %fd18, %fd17, %fd31;
	.loc	1 50 1
	ld.global.nc.u32 	%r34, [%rd34+4];
	.loc	1 52 1
	mul.wide.s32 	%rd39, %r34, 8;
	add.s64 	%rd40, %rd10, %rd39;
	ld.global.f64 	%fd20, [%rd38+8];
	ld.global.f64 	%fd21, [%rd40];
	fma.rn.f64 	%fd22, %fd21, %fd20, %fd19;
	.loc	1 50 1
	ld.global.nc.u32 	%r35, [%rd34+8];
	.loc	1 52 1
	mul.wide.s32 	%rd41, %r35, 8;
	add.s64 	%rd42, %rd10, %rd41;
	ld.global.f64 	%fd23, [%rd38+16];
	ld.global.f64 	%fd24, [%rd42];
	fma.rn.f64 	%fd25, %fd24, %fd23, %fd22;
	.loc	1 50 1
	ld.global.nc.u32 	%r36, [%rd34+12];
	.loc	1 52 1
	mul.wide.s32 	%rd43, %r36, 8;
	add.s64 	%rd44, %rd10, %rd43;
	ld.global.f64 	%fd26, [%rd38+24];
	ld.global.f64 	%fd27, [%rd44];
	fma.rn.f64 	%fd31, %fd27, %fd26, %fd25;
	.loc	1 49 1
	add.s32 	%r41, %r41, 4;
	.loc	1 52 1
	add.s32 	%r40, %r40, -4;
	.loc	1 49 1
	setp.gt.s32 	%p7, %r40, 0;
	@%p7 bra 	$L__BB0_9;

$L__BB0_10:
	.loc	1 34 1
	cvta.to.global.u64 	%rd45, %rd15;
	.loc	1 54 1
	shl.b64 	%rd46, %rd53, 32;
	shr.s64 	%rd47, %rd46, 29;
	add.s64 	%rd48, %rd45, %rd47;
	st.global.f64 	[%rd48], %fd31;

$L__BB0_11:
	add.s64 	%rd53, %rd53, %rd3;
	sub.s32 	%r38, %r38, %r1;
	setp.gt.s32 	%p8, %r38, 0;
	@%p8 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_16;

$L__BB0_12:
	.loc	1 34 1
	cvta.to.global.u64 	%rd12, %rd15;
	mov.u32 	%r43, %r22;

$L__BB0_13:
	.pragma "nounroll";
	.loc	1 0 1
	cvt.u32.u64 	%r37, %rd53;
	.loc	1 43 1
	setp.ge.s32 	%p9, %r37, %r22;
	@%p9 bra 	$L__BB0_15;

	.loc	1 54 1
	shl.b64 	%rd49, %rd53, 32;
	shr.s64 	%rd50, %rd49, 29;
	add.s64 	%rd51, %rd12, %rd50;
	mov.u64 	%rd52, 0;
	st.global.u64 	[%rd51], %rd52;

$L__BB0_15:
	add.s64 	%rd53, %rd53, %rd3;
	sub.s32 	%r43, %r43, %r1;
	setp.gt.s32 	%p10, %r43, 0;
	@%p10 bra 	$L__BB0_13;

$L__BB0_16:
	ret;

}
	// .globl	_22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu
.visible .entry _22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu(
	.param .u32 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_0,
	.param .u32 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_1,
	.param .u64 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_2,
	.param .u64 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_3,
	.param .u64 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_4,
	.param .u64 _22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_5
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<20>;
	.reg .b32 	%r<79>;
	.reg .f64 	%fd<55>;
	.reg .b64 	%rd<46>;
	.loc	1 59 0


	ld.param.u32 	%r41, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_0];
	ld.param.u32 	%r70, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_1];
	ld.param.u64 	%rd12, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_2];
	ld.param.u64 	%rd15, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_3];
	ld.param.u64 	%rd13, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_4];
	ld.param.u64 	%rd14, [_22header_files_mat_lib_c_multiply_sparse_matrix_vector_gpu_59_gpu_param_5];
	.loc	1 61 1
	cvta.to.global.u64 	%rd1, %rd15;
	mov.u32 	%r68, %ctaid.x;
	sub.s32 	%r69, %r68, %r70;
	.loc	1 66 1
	mov.u32 	%r3, %nctaid.x;
	.loc	1 64 1
	mov.u32 	%r4, %tid.x;
	sub.s32 	%r5, %r4, %r41;
	shl.b32 	%r43, %r4, 3;
	cvt.s64.s32 	%rd16, %r43;
	mov.u64 	%rd17, S26_2;
	add.s64 	%rd2, %rd17, %rd16;
	mov.u32 	%r6, %ntid.x;
	add.s32 	%r44, %r6, -1;
	shr.s32 	%r45, %r44, 1;
	or.b32  	%r46, %r45, %r44;
	shr.s32 	%r47, %r46, 2;
	or.b32  	%r48, %r47, %r46;
	shr.s32 	%r49, %r48, 4;
	or.b32  	%r50, %r49, %r48;
	shr.s32 	%r51, %r50, 8;
	or.b32  	%r52, %r51, %r50;
	add.s32 	%r7, %r52, 1;
	.loc	1 61 1
	add.s32 	%r53, %r41, -1;
	shr.u32 	%r54, %r53, 7;
	add.s32 	%r55, %r54, 1;
	and.b32  	%r8, %r55, 3;
	add.s32 	%r9, %r4, 128;
	add.s32 	%r10, %r5, 128;
	mul.wide.s32 	%rd3, %r4, 4;
	mul.wide.s32 	%rd4, %r4, 8;
	add.s32 	%r11, %r4, 256;
	add.s32 	%r12, %r5, 256;
	add.s32 	%r13, %r4, 384;
	add.s32 	%r14, %r5, 384;
	cvta.to.global.u64 	%rd18, %rd13;
	cvta.to.global.u64 	%rd22, %rd14;
	cvta.to.global.u64 	%rd43, %rd12;

$L__BB1_1:
	.pragma "nounroll";
	setp.gt.s32 	%p1, %r69, -1;
	@%p1 bra 	$L__BB1_32;

	.loc	1 0 1
	setp.lt.s32 	%p2, %r41, 1;
	mov.f64 	%fd54, 0d0000000000000000;
	.loc	1 62 1
	@%p2 bra 	$L__BB1_30;

	.loc	1 0 1
	setp.eq.s32 	%p3, %r8, 0;
	.loc	1 62 1
	bar.sync 	0;
	.loc	1 64 1
	mul.wide.s32 	%rd19, %r68, 8;
	add.s64 	%rd20, %rd18, %rd19;
	ld.global.nc.u64 	%rd21, [%rd20];
	cvta.to.global.u64 	%rd5, %rd21;
	add.s64 	%rd23, %rd22, %rd19;
	ld.global.u64 	%rd24, [%rd23];
	cvta.to.global.u64 	%rd6, %rd24;
	mov.f64 	%fd48, 0d0000000000000000;
	mov.u32 	%r71, %r4;
	mov.u32 	%r72, %r5;
	mov.u32 	%r73, %r41;
	@%p3 bra 	$L__BB1_12;

	.loc	1 0 1
	setp.gt.s32 	%p4, %r5, -1;
	.loc	1 64 1
	add.s64 	%rd7, %rd5, %rd3;
	add.s64 	%rd8, %rd6, %rd4;
	mov.f64 	%fd48, 0d0000000000000000;
	.loc	1 63 1
	@%p4 bra 	$L__BB1_6;

	.loc	1 64 1
	ld.global.u32 	%r56, [%rd7];
	mul.wide.s32 	%rd25, %r56, 8;
	add.s64 	%rd26, %rd1, %rd25;
	ld.global.f64 	%fd25, [%rd8];
	ld.global.f64 	%fd26, [%rd26];
	fma.rn.f64 	%fd48, %fd26, %fd25, 0d0000000000000000;

$L__BB1_6:
	.loc	1 0 1
	add.s32 	%r73, %r41, -128;
	setp.eq.s32 	%p5, %r8, 1;
	.loc	1 64 1
	mov.u32 	%r71, %r9;
	mov.u32 	%r72, %r10;
	@%p5 bra 	$L__BB1_12;

	.loc	1 0 1
	setp.gt.s32 	%p6, %r10, -1;
	.loc	1 63 1
	@%p6 bra 	$L__BB1_9;

	.loc	1 64 1
	ld.global.u32 	%r57, [%rd7+512];
	mul.wide.s32 	%rd27, %r57, 8;
	add.s64 	%rd28, %rd1, %rd27;
	ld.global.f64 	%fd27, [%rd8+1024];
	ld.global.f64 	%fd28, [%rd28];
	fma.rn.f64 	%fd48, %fd28, %fd27, %fd48;

$L__BB1_9:
	.loc	1 0 1
	add.s32 	%r73, %r41, -256;
	setp.eq.s32 	%p7, %r8, 2;
	.loc	1 64 1
	mov.u32 	%r71, %r11;
	mov.u32 	%r72, %r12;
	@%p7 bra 	$L__BB1_12;

	.loc	1 0 1
	setp.gt.s32 	%p8, %r12, -1;
	add.s32 	%r73, %r41, -384;
	.loc	1 63 1
	mov.u32 	%r71, %r13;
	mov.u32 	%r72, %r14;
	@%p8 bra 	$L__BB1_12;

	.loc	1 64 1
	ld.global.u32 	%r58, [%rd7+1024];
	mul.wide.s32 	%rd29, %r58, 8;
	add.s64 	%rd30, %rd1, %rd29;
	ld.global.f64 	%fd29, [%rd8+2048];
	ld.global.f64 	%fd30, [%rd30];
	fma.rn.f64 	%fd48, %fd30, %fd29, %fd48;
	mov.u32 	%r71, %r13;
	mov.u32 	%r72, %r14;

$L__BB1_12:
	.loc	1 61 1
	setp.lt.u32 	%p9, %r53, 384;
	.loc	1 64 1
	@%p9 bra 	$L__BB1_23;

	.loc	1 63 1
	add.s32 	%r74, %r71, 384;

$L__BB1_14:
	add.s32 	%r60, %r74, -384;
	.loc	1 64 1
	mul.wide.s32 	%rd31, %r60, 4;
	add.s64 	%rd9, %rd5, %rd31;
	mul.wide.s32 	%rd32, %r60, 8;
	add.s64 	%rd10, %rd6, %rd32;
	.loc	1 63 1
	setp.gt.s32 	%p10, %r72, -1;
	@%p10 bra 	$L__BB1_16;

	.loc	1 64 1
	ld.global.u32 	%r61, [%rd9];
	mul.wide.s32 	%rd33, %r61, 8;
	add.s64 	%rd34, %rd1, %rd33;
	ld.global.f64 	%fd31, [%rd10];
	ld.global.f64 	%fd32, [%rd34];
	fma.rn.f64 	%fd48, %fd32, %fd31, %fd48;

$L__BB1_16:
	add.s32 	%r29, %r72, 128;
	.loc	1 63 1
	setp.gt.s32 	%p11, %r29, -1;
	@%p11 bra 	$L__BB1_18;

	.loc	1 64 1
	ld.global.u32 	%r62, [%rd9+512];
	mul.wide.s32 	%rd35, %r62, 8;
	add.s64 	%rd36, %rd1, %rd35;
	ld.global.f64 	%fd33, [%rd10+1024];
	ld.global.f64 	%fd34, [%rd36];
	fma.rn.f64 	%fd48, %fd34, %fd33, %fd48;

$L__BB1_18:
	.loc	1 63 1
	add.s32 	%r30, %r29, 128;
	setp.gt.s32 	%p12, %r30, -1;
	@%p12 bra 	$L__BB1_20;

	.loc	1 64 1
	ld.global.u32 	%r63, [%rd9+1024];
	mul.wide.s32 	%rd37, %r63, 8;
	add.s64 	%rd38, %rd1, %rd37;
	ld.global.f64 	%fd35, [%rd10+2048];
	ld.global.f64 	%fd36, [%rd38];
	fma.rn.f64 	%fd48, %fd36, %fd35, %fd48;

$L__BB1_20:
	.loc	1 63 1
	add.s32 	%r31, %r30, 128;
	setp.gt.s32 	%p13, %r31, -1;
	@%p13 bra 	$L__BB1_22;

	.loc	1 64 1
	ld.global.u32 	%r64, [%rd9+1536];
	mul.wide.s32 	%rd39, %r64, 8;
	add.s64 	%rd40, %rd1, %rd39;
	ld.global.f64 	%fd37, [%rd10+3072];
	ld.global.f64 	%fd38, [%rd40];
	fma.rn.f64 	%fd48, %fd38, %fd37, %fd48;

$L__BB1_22:
	add.s32 	%r74, %r74, 512;
	add.s32 	%r73, %r73, -512;
	setp.gt.s32 	%p14, %r73, 0;
	add.s32 	%r72, %r31, 128;
	@%p14 bra 	$L__BB1_14;

$L__BB1_23:
	st.shared.f64 	[%rd2], %fd48;
	mov.u32 	%r77, %r6;
	mov.u32 	%r78, %r7;
	bra.uni 	$L__BB1_24;

$L__BB1_26:
	shl.b32 	%r67, %r78, 3;
	cvt.s64.s32 	%rd41, %r67;
	add.s64 	%rd42, %rd2, %rd41;
	ld.shared.f64 	%fd39, [%rd42];
	ld.shared.f64 	%fd40, [%rd2];
	add.f64 	%fd41, %fd40, %fd39;
	st.shared.f64 	[%rd2], %fd41;
	mov.u32 	%r77, %r78;

$L__BB1_24:
	bar.sync 	0;
	setp.lt.s32 	%p15, %r78, 2;
	@%p15 bra 	$L__BB1_27;

	bar.sync 	0;
	add.s32 	%r65, %r78, 1;
	shr.s32 	%r78, %r65, 1;
	add.s32 	%r66, %r78, %r4;
	setp.ge.s32 	%p16, %r66, %r77;
	mov.u32 	%r77, %r78;
	@%p16 bra 	$L__BB1_24;
	bra.uni 	$L__BB1_26;

$L__BB1_27:
	.loc	1 0 1
	setp.ne.s32 	%p17, %r4, 0;
	mov.f64 	%fd54, 0d0000000000000000;
	.loc	1 64 1
	@%p17 bra 	$L__BB1_29;

	ld.shared.f64 	%fd54, [%rd2];

$L__BB1_29:
	bar.sync 	0;

$L__BB1_30:
	.loc	1 0 1
	setp.ne.s32 	%p18, %r4, 0;
	.loc	1 64 1
	@%p18 bra 	$L__BB1_32;

	.loc	1 66 1
	mul.wide.s32 	%rd44, %r68, 8;
	add.s64 	%rd45, %rd43, %rd44;
	st.global.f64 	[%rd45], %fd54;

$L__BB1_32:
	add.s32 	%r68, %r68, %r3;
	add.s32 	%r69, %r69, %r3;
	sub.s32 	%r70, %r70, %r3;
	setp.gt.s32 	%p19, %r70, 0;
	@%p19 bra 	$L__BB1_1;

	ret;

}

	.file	1 "/home/akash/memphys_linux/header_files/mat_lib.c"
